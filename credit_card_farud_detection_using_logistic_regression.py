# -*- coding: utf-8 -*-
"""Credit Card Farud Detection Using Logistic Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/133aYknZvY7m8TH43Z2ky9i-HvwKBba1w

# Credit Card Farud Detection Using Logistic Regression
Aurthor :Irfan Ullah Khan

[![GitHub](https://img.shields.io/badge/GitHub-Profile-blue?style=for-the-badge&logo=github)](https://github.com/programmarself)
[![Kaggle](https://img.shields.io/badge/Kaggle-Profile-blue?style=for-the-badge&logo=kaggle)](https://www.kaggle.com/programmarself)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/irfan-ullah-khan-4a2871208/)  

[![YouTube](https://img.shields.io/badge/YouTube-Profile-red?style=for-the-badge&logo=youtube)](https://www.youtube.com/@irfanullahkhan7748)
[![Email](https://img.shields.io/badge/Email-Contact%20Me-red?style=for-the-badge&logo=email)](mailto:programmarself@gmail.com)

### Importing Necessary Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv("/content/fraudTest.csv")

df.info()

df.describe()

df.head()

df.tail()

df

df.shape

#Checking for null values through function and heatmap
df.isnull().any()

plt.figure(figsize = (20,10))
sns.heatmap(df.isnull())

df.dtypes

dataset_2 = df.drop(columns = 'is_fraud')

dataset_2.corrwith(df['is_fraud']).plot.bar(figsize = (20,10), title = ' correlation index', rot = 45, grid = True)

corr =  df.corr()
plt.figure(figsize = (35,15))
sns.heatmap(corr, annot = True, cmap = 'coolwarm', linewidth = 2)

#findind the features with high correlation
high_corr = df.corr()
high_corr_features = high_corr.index[abs(high_corr['is_fraud'] > 0.5)]

high_corr_features

x = df.drop(columns = 'is_fraud')

y = df['is_fraud']

x

y

df.groupby('is_fraud').mean()

x=df.drop('is_fraud',axis=1)

y=df['is_fraud']

y.shape

x.shape

missing_values = y.isnull().sum()
if missing_values.any():
    print("There are missing values in 'y'.")

# Option 2: Impute missing values
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="mean")
y = imputer.fit_transform(y.to_frame().values)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42)

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

x_train = x_train.drop('trans_date_trans_time', axis=1)

print(x_train.head())

print(x_train.dtypes)

x_train = x_train.drop('trans_num', axis=1)

print(x_train.columns)
print(x_test.columns)

missing_cols = set(x_train.columns) - set(x_test.columns)
if missing_cols:
    raise ValueError(f"Missing columns in x_test: {missing_cols}")

x_test.columns

print("Columns in x_train:", x_train.columns)
print("Columns in x_test:", x_test.columns)

# Check and align columns in x_train and x_test
common_columns = set(x_train.columns) & set(x_test.columns)
x_train = x_train[common_columns]
x_test = x_test[common_columns]

# Now, fit and predict
model = LogisticRegression()
model.fit(x_train, y_train)
ypred = model.predict(x_test)

accuracy_score(ypred,y_test)*100

